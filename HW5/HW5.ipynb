{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvlab/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# load and preprocess the MNIST for anamoly detection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# filter the dataset for digits 1,3,5,7\n",
    "target_digits = [1, 3, 5, 7] \n",
    "target_indices = [i for i, (img, label) in enumerate(mnist_data) if label in target_digits]\n",
    "nontarget_indices = [i for i, (img, label) in enumerate(mnist_data) if label not in target_digits]\n",
    "\n",
    "train_target_indices, val_target_indices = train_test_split(target_indices, test_size=0.2, random_state=42)\n",
    "val_indices = nontarget_indices + val_target_indices\n",
    "\n",
    "train_dataset = Subset(mnist_data, train_target_indices)\n",
    "val_dataset = Subset(mnist_data, val_indices)\n",
    "\n",
    "label_mapping = {1: 0, 3: 1, 5: 2, 7: 3}\n",
    "\n",
    "def map_labels(batch):\n",
    "    inputs, labels = zip(*batch)\n",
    "    labels = torch.tensor([label_mapping[label] for label in labels])\n",
    "    inputs = torch.stack(inputs)\n",
    "    return inputs, labels\n",
    "\n",
    "# dataloader for the filtered dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=map_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train an image classifier that can recognize 1,3,5,7 then use it to do abnormal detection on the handwrittrn images other than 1,3,5,7\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net = net.to(device)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 120.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.1976, Train Accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 152.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.0416, Train Accuracy: 0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 153.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.0259, Train Accuracy: 0.9910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:01<00:00, 155.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.0221, Train Accuracy: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:01<00:00, 155.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.0156, Train Accuracy: 0.9954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 151.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.0129, Train Accuracy: 0.9958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:01<00:00, 154.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.0120, Train Accuracy: 0.9960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 152.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.0097, Train Accuracy: 0.9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 153.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.0092, Train Accuracy: 0.9970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 152.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.0075, Train Accuracy: 0.9977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_acc = correct / total\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss / len(train_loader):.4f}, Train Accuracy: {train_acc:.4f}')\n",
    "\n",
    "\n",
    "torch.save(net.state_dict(), './iamge_classifier.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:03<00:00, 173.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.3161, Max F1 Score: 0.9352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def find_optimal_threshold(model, loader):\n",
    "    model.eval()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    all_scores = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = softmax(outputs)\n",
    "            max_probs, _ = torch.max(probabilities, dim=1)\n",
    "\n",
    "            all_scores.extend(max_probs.cpu().numpy())\n",
    "            \n",
    "            true_labels.extend([(label not in [1, 3, 5, 7]) for label in labels.cpu().numpy()])\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(true_labels, all_scores, pos_label=True)\n",
    "\n",
    "    # use f1-score to find the best threshold\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    optimal_idx = np.argmax(f1_scores[np.isfinite(f1_scores)])  # ignore NaN\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold, f1_scores[optimal_idx]\n",
    "\n",
    "net.load_state_dict(torch.load('./iamge_classifier.pth'))\n",
    "net = net.to(device)\n",
    "\n",
    "optimal_threshold, max_f1_score = find_optimal_threshold(net, val_loader)\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}, Max F1 Score: {max_f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal autoencoder|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 3) \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Sigmoid()  # use Sigmoid to output between [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 146.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 146.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 146.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.6365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 147.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.6312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 147.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.6181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 147.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.5995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 146.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.5935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 148.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.5899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 148.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.5862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 148.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train_autoencoder(model, train_loader, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for data in tqdm(train_loader):\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.view(inputs.size(0), -1).to(device)  \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}')\n",
    "\n",
    "train_autoencoder(autoencoder, train_loader)\n",
    "\n",
    "torch.save(autoencoder.state_dict(), './autoencoder.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:03<00:00, 171.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.4451, Max F1 Score: 0.9477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_autoencoder(model, val_loader):\n",
    "    model.eval()\n",
    "    reconstruction_errors = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(val_loader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.view(inputs.size(0), -1).to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.mean((outputs - inputs) ** 2, dim=1)  ## MSE \n",
    "            reconstruction_errors.extend(loss.cpu().numpy())\n",
    "            true_labels.extend([(label not in [1, 3, 5, 7]) for label in labels.cpu().numpy()])\n",
    "\n",
    "    # 计算阈值\n",
    "    errors = np.array(reconstruction_errors)\n",
    "    # threshold = np.percentile(errors, 95)  # use 95 percentile as threshold\n",
    "    # return threshold\n",
    "    precisions, recalls, thresholds = precision_recall_curve(true_labels, errors, pos_label=True)\n",
    "\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold, f1_scores[optimal_idx]\n",
    "\n",
    "\n",
    "autoencoder.load_state_dict(torch.load('./autoencoder.pth'))\n",
    "optimal_threshold, max_f1_score = evaluate_autoencoder(autoencoder, val_loader)\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}, Max F1 Score: {max_f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 3)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 147.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 149.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 149.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.6269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 147.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.6142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 146.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.6065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 148.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.6012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 149.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.5969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 149.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.5932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 148.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 146.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.5868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def add_noise(inputs, noise_factor=0.5):\n",
    "    noise = torch.randn_like(inputs) * noise_factor\n",
    "    return inputs + noise\n",
    "\n",
    "def train_denoising_autoencoder(model, train_loader, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for data in tqdm(train_loader):\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.view(inputs.size(0), -1).to(device)  # flatten image\n",
    "            noisy_inputs = add_noise(inputs)  \n",
    "            noisy_inputs = noisy_inputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(noisy_inputs)\n",
    "            loss = criterion(outputs, inputs) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}')\n",
    "\n",
    "denoising_autoencoder = DenoisingAutoencoder().to(device)\n",
    "optimizer = torch.optim.Adam(denoising_autoencoder.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_denoising_autoencoder(denoising_autoencoder, train_loader)\n",
    "torch.save(denoising_autoencoder.state_dict(), './denoising_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:03<00:00, 170.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.4493, Max F1 Score: 0.9475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "denoising_autoencoder.load_state_dict(torch.load('./denoising_autoencoder.pth'))\n",
    "optimal_threshold, max_f1_score = evaluate_autoencoder(denoising_autoencoder, val_loader)\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}, Max F1 Score: {max_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 148.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 904820921035.1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 147.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 464121322654325888.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 148.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 11252917674078142.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 148.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 394765950771707.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 148.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: -10422526712174.9062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 149.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Loss: -18185076265080.0781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 148.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Loss: -30528059717278.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 148.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Average Loss: -48647261350374.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 147.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Average Loss: -73014662846243.8594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [00:02<00:00, 148.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: -104118362581852.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)  # 均值\n",
    "        self.fc22 = nn.Linear(400, 20)  # 对数方差\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 28*28)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar) + 1e-6\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return self.fc4(h3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 28*28))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    bce_loss = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "    BCE = bce_loss(recon_x, x.view(-1, 28*28))\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    #print(\"BCE:\",BCE)\n",
    "    #print(\"KLD:\",KLD)\n",
    "    return BCE + KLD\n",
    "\n",
    "# Model, Optimizer and Loss\n",
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training VAE\n",
    "def train_vae(model, train_loader, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        for data, _ in tqdm(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = loss_function(recon_batch, data, mu, logvar)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch + 1}, Average Loss: {train_loss / len(train_loader):.4f}')\n",
    "\n",
    "train_vae(model, train_loader)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'vae.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:03<00:00, 171.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 5929.6426, Max F1 Score: 0.9352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def find_optimal_threshold_vae(model, val_loader):\n",
    "    model.eval()\n",
    "    reconstruction_errors = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, labels in tqdm(val_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            recon_error = F.mse_loss(recon_batch, data.view(-1, 28*28), reduction='none').sum(1)\n",
    "            reconstruction_errors.extend(recon_error.cpu().numpy())\n",
    "\n",
    "            true_labels.extend([(label not in [1, 3, 5, 7]) for label in labels.cpu().numpy()])\n",
    "\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(true_labels, reconstruction_errors, pos_label=True)\n",
    "\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    optimal_idx = np.nanargmax(f1_scores)  # 忽略NaN值，找出最大F1分数\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold, f1_scores[optimal_idx]\n",
    "\n",
    "model.load_state_dict(torch.load('vae.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimal_threshold, max_f1_score = find_optimal_threshold_vae(model, val_loader)\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}, Max F1 Score: {max_f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_data_from_dataloader(dataloader):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for images, targets in dataloader:\n",
    "        # 展平图像数据\n",
    "        images = images.view(images.size(0), -1).numpy()\n",
    "        features.append(images)\n",
    "        labels.append(targets.numpy())\n",
    "    # 将列表转换为NumPy数组\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return features, labels\n",
    "\n",
    "# 从DataLoader转换数据\n",
    "X_train, y_train = convert_data_from_dataloader(train_loader)\n",
    "X_val, y_val = convert_data_from_dataloader(val_loader)\n",
    "\n",
    "# 将验证集的标签转换为异常检测格式（1为异常，0为正常）\n",
    "target_digits = [1, 3, 5, 7]\n",
    "y_val_binary = np.isin(y_val, target_digits, invert=True).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold based on F1 score: -0.18516509922054947\n",
      "F1 Score at optimal threshold: 0.9351927593213183\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      1.00      0.22      4912\n",
      "           1       0.00      0.00      0.00     35441\n",
      "\n",
      "    accuracy                           0.12     40353\n",
      "   macro avg       0.06      0.50      0.11     40353\n",
      "weighted avg       0.01      0.12      0.03     40353\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30615/1741515253.py:20: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
      "/home/cvlab/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cvlab/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cvlab/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "# 孤立森林模型初始化\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination='auto', random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "iso_forest.fit(X_train)\n",
    "\n",
    "# 获取决策函数分数来判断异常\n",
    "scores = iso_forest.decision_function(X_val)\n",
    "\n",
    "\n",
    "\n",
    "# 计算精确度、召回率和阈值\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_val_binary, scores)\n",
    "\n",
    "# 计算 F1 分数\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "optimal_idx = np.nanargmax(f1_scores)  # 找到 F1 分数最大的索引\n",
    "optimal_threshold = thresholds[optimal_idx]  # 对应的最佳阈值\n",
    "\n",
    "y_pred = (scores < optimal_threshold).astype(int)\n",
    "\n",
    "print(\"Optimal threshold based on F1 score:\", optimal_threshold)\n",
    "print(\"F1 Score at optimal threshold:\", f1_scores[optimal_idx])\n",
    "print(classification_report(y_val_binary, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvlab/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/cvlab/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 加载预训练的ResNet模型\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Identity()  # 移除最后一层，用于获取特征\n",
    "model.eval()\n",
    "\n",
    "# 设置为不更新梯度\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvlab/anaconda3/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 设置转换，调整大小并归一化\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 调整图像大小以匹配ResNet的输入\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 应用转换\n",
    "def apply_transforms(dataloader):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for images, targets in dataloader:\n",
    "        # 应用转换并扩展为3通道\n",
    "        images = images.repeat(1, 3, 1, 1)  # 从1通道扩展到3通道\n",
    "        images = torch.stack([transform(img) for img in images])\n",
    "        features.append(model(images).detach().numpy())\n",
    "        labels.append(targets.numpy())\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return features, labels\n",
    "\n",
    "# 从 DataLoader 转换数据\n",
    "X_train_features, _ = apply_transforms(train_loader)\n",
    "X_val_features, _ = apply_transforms(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold based on F1 score with features: -0.11632542558040748\n",
      "F1 Score at optimal threshold with features: 0.9352050980961302\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      1.00      0.22      4912\n",
      "           1       0.00      0.00      0.00     35441\n",
      "\n",
      "    accuracy                           0.12     40353\n",
      "   macro avg       0.06      0.50      0.11     40353\n",
      "weighted avg       0.01      0.12      0.03     40353\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30615/1206498076.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# 使用孤立森林\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination='auto', random_state=42)\n",
    "iso_forest.fit(X_train_features)\n",
    "\n",
    "# 获取决策函数分数\n",
    "val_scores = iso_forest.decision_function(X_val_features)\n",
    "\n",
    "# 计算最佳阈值\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_val_binary, val_scores)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "optimal_idx = np.nanargmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# 预测\n",
    "y_pred_features = (val_scores < optimal_threshold).astype(int)\n",
    "\n",
    "# 输出结果\n",
    "print(\"Optimal threshold based on F1 score with features:\", optimal_threshold)\n",
    "print(\"F1 Score at optimal threshold with features:\", f1_scores[optimal_idx])\n",
    "print(classification_report(y_val_binary, y_pred_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "collection = chroma_client.create_collection(name=\"qa_collection\")\n",
    "collection.add(\n",
    "    documents=[\"Cloud computing is a technology that allows for the storage, management, and processing of data on remote servers accessed via the internet, rather than on local servers or personal computers. It enables users and businesses to utilize online services to run applications or store data.\", \n",
    "               \"Mental health refers to the state of someone's emotional, psychological, and social well-being. A person with good mental health can handle daily stresses, perform productive work, and contribute to their community.\",\n",
    "               \"The ancient Egyptians built pyramids primarily as tombs for the pharaohs, the rulers of ancient Egypt. They served to house their remains and belongings for use in the afterlife. The size and complexity of the pyramids reflect the pharaohs' power and religious beliefs about the afterlife.\"\n",
    "            ],\n",
    "    metadatas=[{'source':'Tech'},\n",
    "               {'source':'Healthy'},\n",
    "               {'source':'geography'}\n",
    "            ],\n",
    "    ids=['doc_tech','doc_health','doc_geo']\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most relevant information:\n",
      "Document ID: doc_tech\n",
      "Content: Cloud computing is a technology that allows for the storage, management, and processing of data on remote servers accessed via the internet, rather than on local servers or personal computers. It enables users and businesses to utilize online services to run applications or store data.\n",
      "Metadata: {'source': 'Tech'}\n",
      "-----\n",
      "Most relevant information:\n",
      "Document ID: doc_health\n",
      "Content: Mental health refers to the state of someone's emotional, psychological, and social well-being. A person with good mental health can handle daily stresses, perform productive work, and contribute to their community.\n",
      "Metadata: {'source': 'Healthy'}\n",
      "-----\n",
      "Most relevant information:\n",
      "Document ID: doc_geo\n",
      "Content: The ancient Egyptians built pyramids primarily as tombs for the pharaohs, the rulers of ancient Egypt. They served to house their remains and belongings for use in the afterlife. The size and complexity of the pyramids reflect the pharaohs' power and religious beliefs about the afterlife.\n",
      "Metadata: {'source': 'geography'}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "def query(question_text):\n",
    "    results = collection.query(\n",
    "        query_texts = [question_text],\n",
    "        n_results = 1\n",
    "    )\n",
    "\n",
    "    print(\"Most relevant information:\")\n",
    "    print(f\"Document ID: {results['ids'][0][0]}\")\n",
    "    print(f\"Content: {results['documents'][0][0]}\")\n",
    "    print(f\"Metadata: {results['metadatas'][0][0]}\")\n",
    "    print(\"-----\")\n",
    "\n",
    "query(\"What is cloud computing?\")\n",
    "query(\"What is mental health?\")\n",
    "query(\"Why did the ancient Egyptians build pyramids?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 338M/338M [00:03<00:00, 104MiB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    return preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "def prepare_text(description):\n",
    "    return clip.tokenize([description]).to(device)\n",
    "\n",
    "def compare_image_text(image_path, description):\n",
    "    image = load_image(image_path)\n",
    "    text = prepare_text(description)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        text_features = model.encode_text(text)\n",
    "\n",
    "        # Correctly calculate the similarity score using cosine similarity and logit scale\n",
    "        logit_scale = model.logit_scale.exp()\n",
    "        logits_per_image = logit_scale * image_features @ text_features.t()\n",
    "        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    return probs[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: 'A monkey sitting by trash bins on a city street, looking directly at the camera.'\n",
      "Match Probability: 1.00\n",
      "\n",
      "Description: 'A large animal searching through garbage in an urban environment.'\n",
      "Match Probability: 1.00\n",
      "\n",
      "Description: 'A cat sitting on a sunny window ledge overlooking a busy street.'\n",
      "Match Probability: 1.00\n",
      "\n",
      "Description: 'An animal outside during the daytime.'\n",
      "Match Probability: 1.00\n",
      "\n",
      "Description: 'A dog rummaging through trash bags near a park bench on a rainy day.'\n",
      "Match Probability: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_path = \"./my_bro.png\"  # Change to your actual image path\n",
    "\n",
    "# Descriptions to test with the image\n",
    "descriptions = [\n",
    "    \"A monkey sitting by trash bins on a city street, looking directly at the camera.\",\n",
    "    \"A large animal searching through garbage in an urban environment.\",\n",
    "    \"A cat sitting on a sunny window ledge overlooking a busy street.\",\n",
    "    \"An animal outside during the daytime.\",\n",
    "    \"A dog rummaging through trash bags near a park bench on a rainy day.\"\n",
    "]\n",
    "\n",
    "# Loop through each description and compute the match probability\n",
    "for description in descriptions:\n",
    "    match_probability = compare_image_text(image_path, description)\n",
    "    print(f\"Description: '{description}'\")\n",
    "    print(f\"Match Probability: {match_probability:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Monkey in Urban Environment\n",
      "Description: 'A monkey beside trash bins in a busy urban setting.' - Probability: 0.0000\n",
      "Description: 'A monkey climbing on a metal barrier near trash bins.' - Probability: 0.0000\n",
      "Description: 'A monkey peering out from behind city trash bins.' - Probability: 1.0000\n",
      "\n",
      "Category: Animal Interactions with Trash\n",
      "Description: 'A raccoon rummaging through trash bins in a city.' - Probability: 1.0000\n",
      "Description: 'A dog sniffing around garbage bags in an alley.' - Probability: 0.0000\n",
      "Description: 'A cat hiding behind trash bins on a sidewalk.' - Probability: 0.0000\n",
      "\n",
      "Category: Urban Wildlife\n",
      "Description: 'A bird perched on trash bins in a city.' - Probability: 0.0000\n",
      "Description: 'A squirrel scavenging near city trash bins.' - Probability: 0.0000\n",
      "Description: 'A rat running around near urban garbage.' - Probability: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device=device)\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    return preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "def prepare_text(descriptions):\n",
    "    return clip.tokenize(descriptions).to(device)\n",
    "\n",
    "def compare_image_text(image_path, descriptions):\n",
    "    image = load_image(image_path)\n",
    "    texts = prepare_text(descriptions)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        text_features = model.encode_text(texts)\n",
    "\n",
    "        logit_scale = model.logit_scale.exp()\n",
    "        logits_per_image = logit_scale * image_features @ text_features.t()\n",
    "        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    return probs.flatten()\n",
    "\n",
    "image_path = \"./my_bro.png\"  \n",
    "\n",
    "# descriptions = [\n",
    "#     \"A monkey rummaging through trash bins on a city street.\",\n",
    "#     \"A monkey sitting by trash bins on a city street looking curious.\",\n",
    "#     \"A monkey looking directly at the camera surrounded by trash.\"\n",
    "# ]\n",
    "\n",
    "# # Running the comparison\n",
    "# probabilities = compare_image_text(image_path, descriptions)\n",
    "\n",
    "\n",
    "# # Printing each description with its respective probability\n",
    "# print(\"Descriptions and their matching probabilities:\")\n",
    "# for desc, prob in zip(descriptions, probabilities):\n",
    "#     print(f\"Description: '{desc}' - Probability: {prob:.4f}\")\n",
    "categories = {\n",
    "    \"Monkey in Urban Environment\": [\n",
    "        \"A monkey beside trash bins in a busy urban setting.\",\n",
    "        \"A monkey climbing on a metal barrier near trash bins.\",\n",
    "        \"A monkey peering out from behind city trash bins.\"\n",
    "    ],\n",
    "    \"Animal Interactions with Trash\": [\n",
    "        \"A raccoon rummaging through trash bins in a city.\",\n",
    "        \"A dog sniffing around garbage bags in an alley.\",\n",
    "        \"A cat hiding behind trash bins on a sidewalk.\"\n",
    "    ],\n",
    "    \"Urban Wildlife\": [\n",
    "        \"A bird perched on trash bins in a city.\",\n",
    "        \"A squirrel scavenging near city trash bins.\",\n",
    "        \"A rat running around near urban garbage.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Running the comparisons for each category\n",
    "for category, descriptions in categories.items():\n",
    "    print(f\"Category: {category}\")\n",
    "    probabilities = compare_image_text(image_path, descriptions)\n",
    "    for desc, prob in zip(descriptions, probabilities):\n",
    "        print(f\"Description: '{desc}' - Probability: {prob:.4f}\")\n",
    "    print()  # New line for better separation of categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Topic 1: Classes **\n",
      "'A dog' - Probability: 0.0014\n",
      "'A cat' - Probability: 0.0029\n",
      "'A monkey' - Probability: 0.9956\n",
      "\n",
      "** Topic 2: Generality **\n",
      "'An animal' - Probability: 0.0262\n",
      "'A monkey' - Probability: 0.9219\n",
      "'A Macaca' - Probability: 0.0520\n",
      "\n",
      "** Topic 3: Details **\n",
      "'A monkey' - Probability: 0.0002\n",
      "'A monkey in a trash can' - Probability: 0.3140\n",
      "'An aggressive monkey coming out from a trash can, staring at the camera' - Probability: 0.6860\n",
      "\n",
      "** Topic 4: Wrong class with details **\n",
      "'A dog' - Probability: 0.0010\n",
      "'A dog in a trash can' - Probability: 0.1081\n",
      "'An aggressive dog coming out from a trash can, staring at the camera' - Probability: 0.8911\n",
      "\n",
      "** Topic 5: Correct answers **\n",
      "'A monkey' - Probability: 0.7866\n",
      "'A trash can' - Probability: 0.0925\n",
      "'A plastic bag' - Probability: 0.1207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "# Setup device and load the CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device=device)\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = './my_bro.png'  # Replace with your actual image file path\n",
    "image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "\n",
    "# Define the topics and corresponding descriptions\n",
    "topics = [\n",
    "    \"Classes\",\n",
    "    \"Generality\",\n",
    "    \"Details\",\n",
    "    \"Wrong class with details\",\n",
    "    \"Correct answers\",\n",
    "]\n",
    "texts = [\n",
    "    [\"A dog\", \"A cat\", \"A monkey\"],  # Classes\n",
    "    [\"An animal\", \"A monkey\", \"A Macaca\"],  # Generality\n",
    "    [\"A monkey\", \"A monkey in a trash can\", \"An aggressive monkey coming out from a trash can, staring at the camera\"],  # Details\n",
    "    [\"A dog\", \"A dog in a trash can\", \"An aggressive dog coming out from a trash can, staring at the camera\"],  # Wrong class with details\n",
    "    [\"A monkey\", \"A trash can\", \"A plastic bag\"],  # Correct answers\n",
    "]\n",
    "\n",
    "# Compare image with texts and calculate probabilities\n",
    "for i, comparing_texts in enumerate(texts):\n",
    "    text_tokens = clip.tokenize(comparing_texts).to(device)\n",
    "\n",
    "    # Compute logits and probabilities\n",
    "    with torch.no_grad():\n",
    "        logits_per_image, _ = model(image, text_tokens)\n",
    "        probabilities = logits_per_image.softmax(dim=-1).cpu().numpy()[0]\n",
    "\n",
    "    # Print the results for each topic\n",
    "    print(f\"** Topic {i + 1}: {topics[i]} **\")\n",
    "    for text, prob in zip(comparing_texts, probabilities):\n",
    "        print(f\"'{text}' - Probability: {prob:.4f}\")\n",
    "    print()  # For better readability between topics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
